{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14cc2511-9dc1-45f7-b9d9-c2a2f4172c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2330d23e-573d-40b8-8f90-a10b7ada4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to handle data preprocessing\n",
    "class DataPreprocessing:\n",
    "    def __init__(self, max_words=10000, max_len=100):\n",
    "        self.max_words = max_words\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = Tokenizer(num_words=self.max_words)\n",
    "    \n",
    "    def load_data(self, filepath):\n",
    "        # Load the Sentiment140 dataset (you can replace with your own dataset path)\n",
    "        df = pd.read_csv(filepath, encoding='latin-1', header=None)\n",
    "        df.columns = ['target', 'id', 'date', 'query', 'user', 'text']\n",
    "        df = df[['target', 'text']]\n",
    "        df['target'] = df['target'].apply(lambda x: 1 if x == 4 else 0)  # 4 -> positive, 0 -> negative\n",
    "        return df\n",
    "    \n",
    "    def preprocess_text(self, df):\n",
    "        # Clean text (optional: implement more cleaning steps if needed)\n",
    "        df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "        return df\n",
    "    \n",
    "    def tokenize_text(self, df):\n",
    "        # Tokenize the text data\n",
    "        self.tokenizer.fit_on_texts(df['text'])\n",
    "        sequences = self.tokenizer.texts_to_sequences(df['text'])\n",
    "        padded_sequences = pad_sequences(sequences, maxlen=self.max_len)\n",
    "        return padded_sequences\n",
    "    \n",
    "    def encode_labels(self, df):\n",
    "        # Encode labels (0 or 1)\n",
    "        label_encoder = LabelEncoder()\n",
    "        labels = label_encoder.fit_transform(df['target'])\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add783df-9415-4d63-a063-7eb881c9feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to handle the deep learning model\n",
    "class SentimentAnalysisModel:\n",
    "    def __init__(self, max_words=10000, max_len=100, embedding_dim=100, dropout_rate=0.2):\n",
    "        self.max_words = max_words\n",
    "        self.max_len = max_len\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=self.max_words, output_dim=self.embedding_dim, input_length=self.max_len))\n",
    "        model.add(LSTM(128, dropout=self.dropout_rate, recurrent_dropout=self.dropout_rate))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val, batch_size=64, epochs=5):\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n",
    "                                 validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def predict(self, X_input):\n",
    "        return self.model.predict(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca2b199-5f58-40a3-b8ed-7f63d2c2c0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 8477s 424ms/step - loss: 0.4146 - accuracy: 0.8090 - val_loss: 0.3915 - val_accuracy: 0.8210\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 8286s 414ms/step - loss: 0.3787 - accuracy: 0.8291 - val_loss: 0.3806 - val_accuracy: 0.8273\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 7823s 391ms/step - loss: 0.3617 - accuracy: 0.8383 - val_loss: 0.3778 - val_accuracy: 0.8310\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 9150s 458ms/step - loss: 0.3492 - accuracy: 0.8454 - val_loss: 0.3763 - val_accuracy: 0.8318\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 8653s 433ms/step - loss: 0.3394 - accuracy: 0.8505 - val_loss: 0.3778 - val_accuracy: 0.8314\n",
      "10000/10000 [==============================] - 368s 37ms/step - loss: 0.3778 - accuracy: 0.8314\n",
      "Test Loss: 0.37784940004348755, Test Accuracy: 0.8313875198364258\n",
      "1/1 [==============================] - 1s 719ms/step\n",
      "Predictions: [[0.9494    ]\n",
      " [0.92765313]]\n"
     ]
    }
   ],
   "source": [
    "# Main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize Data Preprocessing and Model\n",
    "    data_processor = DataPreprocessing()\n",
    "    sentiment_model = SentimentAnalysisModel()\n",
    "\n",
    "    # Load and preprocess data\n",
    "    df = data_processor.load_data('sentiment400/training.1600000.processed.noemoticon.csv')\n",
    "    df = data_processor.preprocess_text(df)\n",
    "    \n",
    "    # Prepare features and labels\n",
    "    X = data_processor.tokenize_text(df)\n",
    "    y = data_processor.encode_labels(df)\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    sentiment_model.train(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = sentiment_model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "    # Example prediction\n",
    "    sample_text = [\"I love this product!\", \"This is the worst experience ever.\"]\n",
    "    sample_seq = data_processor.tokenize_text(pd.DataFrame(sample_text, columns=['text']))\n",
    "    predictions = sentiment_model.predict(sample_seq)\n",
    "    print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d570224-dd69-4b7a-857d-3a17195e1442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 361s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = sentiment_model.predict(X_test)  # Predict probabilities for X_test\n",
    "y_pred = (y_pred_prob > 0.5).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07e186ec-52b1-486e-b49e-6a2edade3f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62dcb32b-c126-49f5-ba71-2f9bf723dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b76636cf-c68c-42e8-bbf8-a5a48b293648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8314\n",
      "Precision: 0.8288\n",
      "Recall: 0.8367\n",
      "F1-Score: 0.8327\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88dda7fc-ed17-4cfd-b631-9f330401dfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.83      0.83    159494\n",
      "    Positive       0.83      0.84      0.83    160506\n",
      "\n",
      "    accuracy                           0.83    320000\n",
      "   macro avg       0.83      0.83      0.83    320000\n",
      "weighted avg       0.83      0.83      0.83    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for detailed metrics\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Negative\", \"Positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18bd038a-cfef-4ae9-96b0-4537b6bd9b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      " [[131745  27749]\n",
      " [ 26207 134299]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
